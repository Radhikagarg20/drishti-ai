# Requirements Document: Drishti.ai

## 1. Introduction

Drishti.ai is an AI-powered visual trust and fraud detection system designed to combat the growing threat of AI-generated images, manipulated media, and image-based fraud in India. With the rapid advancement of generative AI tools, citizens increasingly encounter fake job offers, forged government notices, fabricated financial screenshots, and misinformation images that are difficult to distinguish from authentic content.

Drishti.ai provides real-time image authenticity verification along with explainable risk insights. The platform empowers citizens, institutions, and organizations to make informed decisions about visual content they receive or encounter online.

---

## 2. Problem Statement

India is experiencing a surge in AI-generated and manipulated images used for:

- Financial scams
- Fake job offers
- Fraudulent government notices
- Social misinformation
- Deepfake-style manipulation
- Edited screenshots for banking fraud

Most citizens lack technical tools to verify the authenticity of such images. There is currently no scalable, easy-to-use, India-focused visual verification system that provides real-time analysis and understandable explanations.

Drishti.ai aims to fill this gap.

---

## 3. Objectives

- Detect AI-generated images
- Detect manipulated or edited real images
- Analyze visual artifacts and inconsistencies
- Provide explainable AI-based risk assessments
- Enable real-time verification
- Support scalable deployment for large user bases

---

## 4. Scope

### In Scope
- Image upload and analysis
- AI-generated image detection
- Manipulation detection
- Risk scoring system
- Human-readable explanation output
- Cloud-based scalable architecture

### Out of Scope (Phase 1)
- Video deepfake detection
- Audio manipulation detection
- Full forensic legal certification

---

## 5. Stakeholders

- General Citizens
- Students and Professionals
- Banks and Fintech Platforms
- Media and Fact-Checking Organizations
- Government and Public Safety Bodies

---

## 6. Glossary

- **Drishti_System**: Complete AI-powered visual trust platform
- **Image_Analyzer**: Component that processes uploaded images
- **Detection_Engine**: Core AI/ML engine detecting AI-generated or manipulated content
- **Artifact_Detector**: Module identifying visual inconsistencies
- **Risk_Scorer**: Module generating risk score
- **Explainability_Module**: Generates human-readable explanations
- **Risk_Report**: Final output including classification and explanation

---

## 7. Functional Requirements

### FR-1: Image Upload
The system shall allow users to upload images in standard formats (JPEG, PNG).

### FR-2: AI-Generated Image Detection
The system shall analyze uploaded images to determine whether they were generated by AI models such as GANs or diffusion-based models.

### FR-3: Manipulation Detection
The system shall detect alterations, edits, or tampering in real images.

### FR-4: Artifact Analysis
The system shall analyze visual artifacts including:
- Lighting inconsistencies
- Texture anomalies
- Shadow irregularities
- Edge artifacts
- Compression inconsistencies

### FR-5: Metadata Inspection
The system shall inspect image metadata for suspicious patterns.

### FR-6: Risk Scoring
The system shall generate a risk score (0–100) indicating probability of manipulation or AI generation.

### FR-7: Explainable Output
The system shall provide a human-readable explanation describing why the image is flagged.

### FR-8: Real-Time Processing
The system shall provide results within a few seconds of upload.

### FR-9: API Support
The system shall provide API endpoints for integration with external platforms.

---

## 8. Non-Functional Requirements

### NFR-1: Performance
The system shall respond within 3–5 seconds under normal load.

### NFR-2: Scalability
The system shall support cloud-based scaling to handle large volumes of requests.

### NFR-3: Security
Uploaded images shall be processed securely and not permanently stored without consent.

### NFR-4: Privacy
The system shall comply with data privacy standards and avoid storing sensitive personal data.

### NFR-5: Reliability
The system shall maintain high availability (99% uptime target).

---

## 9. Assumptions

- Images are submitted in supported formats.
- Public or synthetic datasets are used for AI model training.
- Internet connectivity is available for cloud processing.

---

## 10. Constraints

- Limited access to proprietary forensic datasets.
- Must operate within ethical AI boundaries.
- Must provide explainable outputs to avoid black-box decision issues.

---

## 11. Expected Impact

Drishti.ai aims to:

- Reduce image-based fraud in India
- Improve digital trust
- Protect citizens from misinformation
- Support institutions in fraud detection
- Create scalable visual verification infrastructure for Bharat

---

## 12. Future Enhancements

- Video deepfake detection
- Browser extension integration
- WhatsApp-style image verification integration
- Enterprise fraud detection dashboard
